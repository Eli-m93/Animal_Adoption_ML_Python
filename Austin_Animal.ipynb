{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sodapy import Socrata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting if an Animal will be re-homed in <30 Days Using Government Data.\n",
    "\n",
    "Below is a mini-project I started that attempts to predict if an animal taken in from Austin animal shelter will be re-homed in 30 days. I did this to better understand Tree + Ensemble methods in Sklearn.\n",
    "\n",
    "- This project was inspired by a [mini-course on decision trees from AWS](https://github.com/aws-samples/aws-machine-learning-university-dte).\n",
    "- Raw data is taken from [The City of Austin Texas's government data page](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm).\n",
    "\n",
    "This project is ongoing, please excuse any grammatical mistakes or unfinished parts!\n",
    "\n",
    "### Ongoing goals to add (As of 4/13/22):\n",
    "\n",
    "1. Pull data via SODA API or create local SQL server to perform pulls. Problematic as SODA API won't let me pull \"max rows.\"\n",
    "2. Attempt other ensemble methods. Ideally ADA boosted trees and NN (when I master this).\n",
    "3. Finish with fine tuning and assessing over test set.\n",
    "4. Create final table of results + takeaways.\n",
    "5. Expand on EDA, clean up as part of presentation to Austin Shelter team.\n",
    "6. **NEW 7/2022** Clean up coding syntax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Intake + Prep\n",
    "\n",
    "Cleaning is one of the most important aspects of any project. Below I attempt to:\n",
    "\n",
    "1. Pull in data via API, create datasets\n",
    "2. Find missing or bad data, these rows could skew our analysis, especially if features contain many missing values or behave in unexpected ways.\n",
    "3. Apply cleaning rules to data.\n",
    "4. Merged datasets to have a beginning endline dataset to run EDA over.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grab Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define way to create raw data from API\n",
    "def data_feeder(df):\n",
    "    a = pd.DataFrame.from_records(df)\n",
    "    a.columns = a.iloc[0]\n",
    "    a = a[1:]\n",
    "    # Annoying feature of from_records is that it replaces NaN with ''\n",
    "    a = a.replace('', np.nan)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call API to get Data\n",
    "client = Socrata(\"data.austintexas.gov\", 'HwnJIRk3Ph7NqQ0cPB0MOPkTF')\n",
    "intake = client.get(\"wter-evkm\", limit=99999999, content_type='csv')\n",
    "outcome = client.get(\"9t4d-g238\", limit=99999999, content_type='csv')\n",
    "\n",
    "# Make data\n",
    "intake_df = data_feeder(intake)\n",
    "outcome_df = data_feeder(outcome)\n",
    "geocoded_df = pd.read_csv('geocoded_locations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_records(outcome)\n",
    "a.columns = a.iloc[0]\n",
    "a = a[1:]\n",
    "# Annoying feature of from_records is that it replaces NaN with ''\n",
    "a = a.replace('', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find bad/missing data:\n",
    "\n",
    "Here I am looking for any columns that might be problematic to our analysis (many missing values, extreme values, or nonsensical values that require more digging).\n",
    "\n",
    "I want to automate this, if we find a small amount of NaN's we should be fine to just drop them. If these NaN become a larger issues (lets say > %2) we need to pause and manually inspect what is going on.\n",
    "\n",
    "It should be noted that this notebook is a little backwards, I was able to do a mix of EDA and bad data cleanup in unison but for clarity to an external audience I just separate the two. This means I found odd relationships later into EDA but came back up here to insert cleaning rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a function to output what's missing\n",
    "def percent_missing(df):\n",
    "    percent_nan = 100 * df.isnull().sum() / len(df)\n",
    "    percent_nan = percent_nan[percent_nan > 0].sort_values()\n",
    "    drop_list = percent_nan[(percent_nan < 2) & percent_nan != 0]\n",
    "    if percent_nan.shape[0] == 0:\n",
    "        print(\"No NA values, consider checking the data\")\n",
    "    else:\n",
    "        print(percent_nan)\n",
    "    return drop_list.index.to_list()\n",
    "\n",
    "\n",
    "intake_drop = percent_missing(intake_df)\n",
    "outcome_drop = percent_missing(outcome_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "def lower_case_col(columns):\n",
    "    return columns.replace(\" \", \"_\").lower()\n",
    "\n",
    "\n",
    "def sort_for_merge(var, name):\n",
    "    return var.sort_values(by=[name + '_datetime']).groupby(['animal_id']).cumcount()+1\n",
    "\n",
    "\n",
    "def clean_up(dataframe, droplist, name):\n",
    "    return (dataframe\n",
    "            .rename(columns=lower_case_col)\n",
    "            .assign(name_avail=np.where(dataframe.name.isna(), 0, 1),\n",
    "                    datetime=pd.to_datetime(dataframe.datetime),\n",
    "                    month=lambda x: x.datetime.dt.month\n",
    "                    )\n",
    "            .dropna(subset=droplist)\n",
    "            .rename(columns={'datetime': name+'_datetime'})\n",
    "            .drop(['name'], axis=1)\n",
    "\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to Data\n",
    "intake_df_clean = clean_up(intake_df, intake_drop, 'intake')\n",
    "outcome_df_clean = clean_up(outcome_df, outcome_drop, 'outcome')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge Intake & Outcome Data:\n",
    "\n",
    "Now merge the semi-cleaned data together so I can continue with feature engineering and EDA. To do this I first create merging variables.\n",
    "\n",
    "The same animal can show up multiple times, however their intake and subsequent outcome are always in order. For instance if dog A has been intaken 5 times in our data, then they'll be in the outcome 5 times, if not the animal is still waiting for an outcome. I can't merge these multiple instances on ID and date as an animal will come in a different date it leaves, but I can sort on date in both dataframes and create a unique merge variable instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_for_merge(var):\n",
    "    var['merge_counter'] = var.sort_values(\n",
    "        by=([col for col in var.columns if 'datetime' in col])).groupby(['animal_id']).cumcount()+1\n",
    "\n",
    "\n",
    "sort_for_merge(intake_df_clean)\n",
    "sort_for_merge(outcome_df_clean)\n",
    "\n",
    "# Now merge\n",
    "merged_df = intake_df_clean.merge(outcome_df_clean[[\n",
    "    'outcome_type',\n",
    "    'animal_id',\n",
    "    'outcome_datetime',\n",
    "    'merge_counter']],\n",
    "    on=['animal_id',\n",
    "        'merge_counter'],\n",
    "    how='outer',\n",
    "    indicator=True)\n",
    "\n",
    "# Okay most merged!\n",
    "print(merged_df._merge.value_counts())\n",
    "\n",
    "# lets just keep in the inner product\n",
    "merged_df = merged_df[merged_df._merge == 'both']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA + Feature Engineering\n",
    "\n",
    "This step attempts to combine multiple aspects of any data science project together:\n",
    "\n",
    "1. Identify worthwhile features to use and determine what features to create.\n",
    "2. Create new features. Many of the raw features given are not ready to run EDA over. I need to still fix and create features.\n",
    "3. Perform EDA and identify any issues or interesting relationships.\n",
    "4. Drop observations or clean features of interest.\n",
    "5. Specify features types and transform as needed\n",
    "\n",
    "Feature Engineering is an ongoing process however, so what is listed above is only a portion of what I do on this project. Moreover, this process is an overarching step of this project. Under the hood and behind the curtains lies hundreds of lines of depreciated code, useless features, and other analysis not included. Later on I will continue feature engineering by dummying our variables (after EDA).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Identify\n",
    "\n",
    "First I need to think of what features in the intake data could potentially predict if an animal will be rehomed, I don't want to throw the whole kitchen sink of features in potentially adding noise to my analysis. Second, I need to understand and define \"rehomed.\" What is the key performance metric I should use?\n",
    "\n",
    "Much of this \"Identify\" comes during EDA or via simple inspection of my data. I already know by looking that intake Age is important, breed, and time of adoption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create\n",
    "\n",
    "After Identifying what I could use in the intake data, I need to create additional features and retool existing ones to my liking. Some potential ideas I saw:\n",
    "\n",
    "1. Seasonality might matter, having an animal come in near Christmas might spur higher adoptions.\n",
    "2. Age needs to be standard across animals, lets turn it into months.\n",
    "3. How should we deal with purebred and mixed animals?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make age in terms of months\n",
    "def age_to_num(var):\n",
    "    num, date = var.split(' ')\n",
    "    num = int(num)\n",
    "    if 'year' in date:\n",
    "        num = num*12\n",
    "    elif 'week' in date:\n",
    "        num = num/4\n",
    "    elif 'day' in date:\n",
    "        num = num/30\n",
    "    else:\n",
    "        num\n",
    "    if num < 0:\n",
    "        num = np.nan\n",
    "    return(num)\n",
    "\n",
    "#Add more\n",
    "merged_df = (\n",
    "    merged_df\n",
    "    # Few more X's\n",
    "    .assign(age=merged_df.age_upon_intake.apply(age_to_num),\n",
    "            # Let's make a \"purebred\" variable for dogs. This should only really matter for dogs, as for cats \"shorthair mix\" & \"shorthair\" for a cat are identical. Moreover, what is the difference between a \"cow\" and \"cow mix?\"\n",
    "            purebred=np.where((merged_df.animal_type == \"Dog\") & ~(\n",
    "                merged_df.breed.str.contains(\"Mix|/\")), 1, 0),\n",
    "            days=(merged_df.outcome_datetime -\n",
    "                  merged_df.intake_datetime) / np.timedelta64(1, 'D'),\n",
    "            )\n",
    "    # Start on Y's\n",
    "    .assign(adopted=np.where(merged_df.outcome_type.str.contains('Adopt'), 1, 0),\n",
    "            rehomed=np.where(merged_df.outcome_type.str.contains(\n",
    "                'Adopt|Rto|Return to Owner'), 1, 0),\n",
    "            rehomed_in_30_days=lambda x: np.where(\n",
    "            (x.rehomed == 1) & (x.days <= 30), 1, 0)\n",
    "            )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get an idea of where animals are found with an interactive map:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps\n",
    "def generateBaseMap(default_location=[30, -97.733330], default_zoom_start=10):\n",
    "    base_map = folium.Map(location=default_location,\n",
    "                          control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map\n",
    "\n",
    "\n",
    "basemap = generateBaseMap()\n",
    "\n",
    "folium.TileLayer('cartodbpositron').add_to(basemap)\n",
    "folium.Marker(location=[30.2527847, -97.6926073],\n",
    "              popup='Austin Animal Shelter',\n",
    "              icon=folium.Icon(color='green', icon='info-sign')).add_to(basemap)\n",
    "HeatMap(data=geocoded_df[['latitude', 'longitude']].groupby(['latitude', 'longitude']).sum(\n",
    ").reset_index().values.tolist(), radius=8, max_zoom=13, name='Heat Map').add_to(basemap)\n",
    "folium.LayerControl(collapsed=False).add_to(basemap)\n",
    "basemap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets plot animal age by type. As we can see there's a concerning amount of outliers by animal type in our data (that is observations 1.5\\*IQR + 3Q). This is something we ought to drop later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal ages\n",
    "ax = sns.boxplot(x=\"animal_type\", y=\"age\", showfliers=True, data=merged_df)\n",
    "ax.set_ylabel(\"Age (Months)\")\n",
    "ax.set_xlabel(\"Animal Type\")\n",
    "ax.set_title(\"Average Ages of Animals (All)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there's a fair amount of outliers by animal type, lets fix this now before I move on with EDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_drop(df):\n",
    "    q1 = df.age.quantile(0.25)\n",
    "    q3 = df.age.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    df = df.iloc[np.where((q1 - 1.5*iqr < df.age) &\n",
    "                          (df.age < q3 + 1.5*iqr))[0], :]\n",
    "    return df\n",
    "\n",
    "\n",
    "df = merged_df\n",
    "for i in merged_df.animal_type.unique():\n",
    "    q1 = df[df.animal_type == i].age.quantile(0.25)\n",
    "    q3 = df[df.animal_type == i].age.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    drop_q1 = q1 - 1.5*iqr\n",
    "    drop_q3 = q3 + 1.5*iqr\n",
    "    df = df.drop(df[(df.animal_type == i) &\n",
    "                    (df.age < drop_q1)].index)\n",
    "    df = df.drop(df[(df.animal_type == i) &\n",
    "                    (df.age > drop_q3)].index)\n",
    "\n",
    "merged_df_clean = df\n",
    "\n",
    "\n",
    "ax = sns.boxplot(x=\"animal_type\", y=\"age\",\n",
    "                 showfliers=True, data=merged_df_clean)\n",
    "ax.set_title(\"Ages without Outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='animal_type', y=\"age\", data=merged_df_clean,\n",
    "                    hue='rehomed_in_30_days', split='True', palette='rainbow')\n",
    "ax.set_ylabel(\"Age (Months)\")\n",
    "ax.set_xlabel(\"Animal Type\")\n",
    "ax.set_title(\"Adoption, Age, and Animal Type\")\n",
    "ax.legend(title=\"Rehomed in 30 Days\",\n",
    "          loc='best', fontsize='small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = pd.DataFrame()\n",
    "table_df['Rehomed'] = merged_df_clean['rehomed']\n",
    "table_df['Rehomed Within 30 Days'] = merged_df_clean['rehomed_in_30_days']\n",
    "table_df['Animal Type'] = merged_df_clean['animal_type']\n",
    "table_df['Intake Type'] = merged_df_clean['intake_type']\n",
    "\n",
    "pivot = np.round(pd.pivot_table(table_df, index=['Animal Type'],\n",
    "                                values=['Rehomed', 'Rehomed Within 30 Days'],\n",
    "                                aggfunc=[np.mean, np.sum],\n",
    "                                margins=True,\n",
    "                                margins_name='Total'), 2)\n",
    "\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = np.round(pd.pivot_table(table_df, index=['Intake Type'],\n",
    "                                values=['Rehomed', 'Rehomed Within 30 Days'],\n",
    "                                aggfunc=[np.mean, np.sum],\n",
    "                                margins=True,\n",
    "                                margins_name='Total'), 2)\n",
    "\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='animal_type', data=merged_df_clean).set_title(\n",
    "    \"Count of Animal Types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.catplot(\n",
    "    x='animal_type',\n",
    "    y='rehomed_in_30_days',\n",
    "    col='intake_type',\n",
    "    data=merged_df_clean,\n",
    "    kind='bar',\n",
    "    ci=None\n",
    ")\n",
    "ax.set_ylabels('Adopted Within 30 Days')\n",
    "ax.set_xlabels('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x='outcome_month',\n",
    "            data=merged_df_clean,\n",
    "            fill=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(x): return x.mode() if len(x) > 2 else np.array(x)\n",
    "\n",
    "\n",
    "merged_df_clean.groupby('animal_type')['breed'].agg(mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_clean.groupby('animal_type')['breed'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Strings\n",
    "\n",
    "I have a strong interest in using the animal's name, found location, intake type, condition, breed, and color in our analysis. First I need to actually clean the text before I can vectorize them.\n",
    "\n",
    "As a note: This portion was heavily inspired by the AWS course where they introduced me to text cleaning and vectorization tools.\n",
    "\n",
    "What I have in mind is this:\n",
    "\n",
    "1. Use SnowballStemmer to simplify longer strings like colors, address, or name\n",
    "2. Get rid of useless characters such as \"/\" \"\\*\" \"()\" \".\" in strings\n",
    "3. Remove any white space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First SnowballStemmer\n",
    "\n",
    "# specify stop_words: words that can be ignored when simplifying our strings\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def preProcessText(text):\n",
    "    # lowercase and strip leading/trailing white space\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # remove HTML tags\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "\n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "\n",
    "    # remove extra white space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)\n",
    "\n",
    "\n",
    "# Clean the text features\n",
    "for c in ['name', 'breed', 'color', 'found_location', 'intake_condition']:\n",
    "    print('Text cleaning: ', c)\n",
    "    merged_df_clean[c] = [cleanSentence(\n",
    "        item, stop_words, stemmer) for item in merged_df_clean[c].values]\n",
    "    merged_df[c] = [cleanSentence(item, stop_words, stemmer)\n",
    "                    for item in merged_df[c].values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection & Train Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features + Outcome:\n",
    "\n",
    "After EDA and some manual observation I believe I found a set of interesting features to use to predict adoption and rehoming. To simplfy this process down the road I will specify three type of features that I will use (and subsequently clean).\n",
    "\n",
    "1. Numerical: Any feature that is continuos or ordinal, i.e. the feature is coded in such a way that high or lower values correspond to some implicit ordering or intensity. Think age, income, weight, size, etc..\n",
    "2. Categorical: Any feature that can be broken in discrete values, however unlike ordinal, higher or lower values do not correspond to any ordering or intensity. Think color, breed, etc..\n",
    "3. String: Any feature whose information is encoded as a string, where no well defined structure is present. Think name, address, review, etc..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_clean.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = ['age']\n",
    "cat_feats = ['animal_type', 'intake_month',\n",
    "             'sex_upon_intake', 'intake_condition', 'purebred']\n",
    "# Include color + breed in strings as these features contain multiple values that can be seemingly mixed up. I don't want to treat a pit-bull/lab mix any differently as a lab/put-bull mix.\n",
    "str_feats = ['name', 'color', 'breed', 'found_location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets specify our Y for now:\n",
    "x = num_feats + cat_feats + str_feats\n",
    "y = 'rehomed_in_30_days'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    merged_df, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "# From the test data further split into validation (we use throughout process) & test (use only at end)\n",
    "val_data, test_data = train_test_split(\n",
    "    test_data, test_size=0.5, shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure the training and test data have an equal size amount of outcomes to train over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_0_train = train_data[train_data[y] == 0]\n",
    "outcome_1_train = train_data[train_data[y] == 1]\n",
    "\n",
    "print(f'Class 0 in Training proportion is: {len(outcome_0_train)}')\n",
    "print(f'Class 1 in Training proportion is: {len(outcome_1_train)}')\n",
    "\n",
    "outcome_0_test = test_data[test_data[y] == 0]\n",
    "outcome_1_test = test_data[test_data[y] == 1]\n",
    "\n",
    "print(f'Class 0 in Testing proportion is:{len(outcome_0_test)}')\n",
    "print(f'Class 1 in Testing proportion is:{len(outcome_1_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_class_1_no = outcome_1_train.sample(\n",
    "    n=len(outcome_0_train), replace=True, random_state=1)\n",
    "train_data = pd.concat([outcome_0_train, upsampled_class_1_no])\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "outcome_0_train = train_data[train_data[y] == 0]\n",
    "outcome_1_train = train_data[train_data[y] == 1]\n",
    "\n",
    "print(f'Class 0 in Training proportion is: {len(outcome_0_train)}')\n",
    "print(f'Class 1 in Training proportion is: {len(outcome_1_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data + Build Pipline\n",
    "\n",
    "Below we will process our data (transform categorical into dummies and vectorize text data), then create a pipeline that can take in any new data and work it into our models seamlessly.\n",
    "\n",
    "For numerical values we'll:\n",
    "\n",
    "1. Impute any missing values with the mean (we saw very early on not many age's were missing, so a simple imputation will work well)\n",
    "2. Standardize values (for non-tree models)\n",
    "\n",
    "For categorical we'll:\n",
    "\n",
    "1. Impute any missing with a unique categorical value (missing column = 1)\n",
    "2. Transform into dummies with onehotencoder.\n",
    "\n",
    "For Strings we'll:\n",
    "\n",
    "1. Vectorize (just like creating dummies that equal 1 if the word exist in the row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe_tree = Pipeline([\n",
    "    ('num_tree_imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant',\n",
    "                                  fill_value='missing')),\n",
    "    ('coder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "text_pipe_name = Pipeline([\n",
    "    ('text_vect_name', CountVectorizer(binary=True, max_features=50))\n",
    "])\n",
    "text_pipe_location = Pipeline([\n",
    "    ('text_vect_name', CountVectorizer(binary=True, max_features=150))\n",
    "])\n",
    "text_pipe_breed = Pipeline([\n",
    "    ('text_vect_name', CountVectorizer(binary=True))\n",
    "])\n",
    "text_pipe_color = Pipeline([\n",
    "    ('text_vect_name', CountVectorizer(binary=True, max_features=50))\n",
    "])\n",
    "\n",
    "\n",
    "# Put all into a single transformer\n",
    "tree_transformer = ColumnTransformer([\n",
    "    ('numerical_transform', num_pipe_tree, num_feats),\n",
    "    ('categorical_transform', cat_pipe, cat_feats),\n",
    "    ('text_transform_name', text_pipe_name, str_feats[0]),\n",
    "    ('text_transform_color', text_pipe_color, str_feats[1]),\n",
    "    ('text_transform_breed', text_pipe_breed, str_feats[2]),\n",
    "    ('text_transform_loc', text_pipe_location, str_feats[3])\n",
    "\n",
    "])\n",
    "\n",
    "logit_transformer = ColumnTransformer([\n",
    "    ('numerical_transform', num_pipe, num_feats),\n",
    "    ('categorical_transform', cat_pipe, cat_feats),\n",
    "    ('text_transform_name', text_pipe_name, str_feats[0]),\n",
    "    ('text_transform_color', text_pipe_color, str_feats[1]),\n",
    "    ('text_transform_breed', text_pipe_breed, str_feats[2]),\n",
    "    ('text_transform_loc', text_pipe_location, str_feats[3])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Models to Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train data to train the network\n",
    "X_train = train_data[x]\n",
    "y_train = train_data[y]\n",
    "\n",
    "# Get validation data to validate the network\n",
    "X_val = val_data[x]\n",
    "y_val = val_data[y]\n",
    "\n",
    "# Get test data to test the network\n",
    "X_test = test_data[x]\n",
    "y_test = test_data[y]\n",
    "\n",
    "print('Datasets shapes before processing: ',\n",
    "      X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "a = tree_transformer.fit_transform(X_train)\n",
    "b = tree_transformer.transform(X_val)\n",
    "c = tree_transformer.transform(X_test)\n",
    "\n",
    "print('Datasets shapes after processing: ', a.shape, b.shape, c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic Tree\n",
    "classic_tree = DecisionTreeClassifier(random_state=1)\n",
    "classic = Pipeline([\n",
    "    (\"preprocessor\", tree_transformer),\n",
    "    (\"classic_tree\", classic_tree)\n",
    "])\n",
    "\n",
    "# Random Tree\n",
    "rfc_tree = RandomForestClassifier(random_state=1)\n",
    "rfc = Pipeline([\n",
    "    (\"preprocessor\", tree_transformer),\n",
    "    (\"rfc_tree\", rfc_tree)\n",
    "])\n",
    "\n",
    "# Random Tree\n",
    "ada_tree = AdaBoostClassifier(random_state=1)\n",
    "ada = Pipeline([\n",
    "    (\"preprocessor\", tree_transformer),\n",
    "    (\"ada_tree\", ada_tree)\n",
    "])\n",
    "\n",
    "\n",
    "# log\n",
    "log = Pipeline([\n",
    "    (\"preprocessor\", logit_transformer),\n",
    "    (\"log\", LogisticRegression(max_iter=1000000000000))\n",
    "])\n",
    "\n",
    "# regularized log\n",
    "log_l2_pipe = Pipeline([\n",
    "    (\"preprocessor\", logit_transformer),\n",
    "    (\"log\", LogisticRegression(penalty='l2',\n",
    "                               solver='saga',\n",
    "                               C=.01,\n",
    "                               max_iter=1000))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "rfc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & Run Naive Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "classic.fit(X_train, y_train)\n",
    "ada.fit(X_train, y_train)\n",
    "log.fit(X_train, y_train)\n",
    "log_l2_pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tree.get_params(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_rfc = rfc.predict(X_val)\n",
    "print(\"RFC TREE:\", classification_report(y_val, train_predictions_rfc))\n",
    "train_predictions_class = classic.predict(X_val)\n",
    "print(\"DECISION TREE:\", classification_report(y_val, train_predictions_class))\n",
    "train_predictions_ada = ada.predict(X_val)\n",
    "print(\"ADA TREE:\", classification_report(y_val, train_predictions_ada))\n",
    "train_predictions_log = log.predict(X_val)\n",
    "print(\"LOG:\", classification_report(y_val, train_predictions_log))\n",
    "train_predictions_log_l2 = log_l2_pipe.predict(X_val)\n",
    "print(\"LOG L2:\", classification_report(y_val, train_predictions_log_l2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(rfc['preprocessor'].transformers_[1][1]\n",
    "         ['coder'].get_feature_names(cat_feats))\n",
    "b = list(sorted(rfc['preprocessor'].transformers_[2]\n",
    "         [1]['text_vect_name'].vocabulary_.keys()))\n",
    "c = list(sorted(rfc['preprocessor'].transformers_[3]\n",
    "         [1]['text_vect_name'].vocabulary_.keys()))\n",
    "d = list(sorted(rfc['preprocessor'].transformers_[4]\n",
    "         [1]['text_vect_name'].vocabulary_.keys()))\n",
    "e = list(sorted(rfc['preprocessor'].transformers_[5]\n",
    "         [1]['text_vect_name'].vocabulary_.keys()))\n",
    "\n",
    "cols = ['age'] + a + b + c + d + e\n",
    "\n",
    "coef_tree = pd.DataFrame({'features': cols, 'values': rfc_tree.feature_importances_}).sort_values(\n",
    "    by='values', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "coef_tree.head(10).plot.bar(x='features', ax=ax)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, ha='right')\n",
    "ax.set_title(\"Feature importances using GINI\")\n",
    "ax.set_ylabel(\"Mean Decrease in Impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning Hyperparameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic Tree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for GridSearch\n",
    "param_grid = {'classic_tree__max_depth': [25, 100, 300],  # , 50, 75, 100, 125, 150, 200, 250],\n",
    "              'classic_tree__min_samples_leaf': [5, 10, 15],  # , 25, 30],\n",
    "              # , 25, 30, 45, 50]\n",
    "              'classic_tree__min_samples_split': [2, 5, 15]\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(classic,  # Base model\n",
    "                           param_grid,  # Parameters to try\n",
    "                           cv=5,  # Apply 5-fold cross validation\n",
    "                           verbose=1,  # Print summary\n",
    "                           n_jobs=-1  # Use all available processors\n",
    "                           )\n",
    "\n",
    "# Fit the GridSearch to our training data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "classifier = grid_search.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = classifier.predict(X_val)\n",
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"val accuracy:\", accuracy_score(y_val, val_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch cv on random forest\n",
    "\n",
    "# Parameter grid for GridSearch\n",
    "param_grid = {'rfc_tree__n_estimators': [150],  # , 50, 75, 100, 125, 150, 200, 250],\n",
    "              'rfc_tree__max_features': [.2, .5, 1.0, 'auto'],  # , 25, 30],\n",
    "              # , 50, 75, 100, 125, 150, 200, 250],\n",
    "              'rfc_tree__max_depth': [3, 10, 100],\n",
    "              'rfc_tree__min_samples_split': [2, 5, 50]  # , 25, 30, 45, 50]\n",
    "              }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(rfc,  # Base model\n",
    "                           param_grid,  # Parameters to try\n",
    "                           cv=5,  # Apply 5-fold cross validation\n",
    "                           verbose=10,  # Print summary\n",
    "                           )\n",
    "\n",
    "# Fit the GridSearch to our training data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "classifier = grid_search.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "val_predictions = classifier.predict(X_val)\n",
    "\n",
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"val accuracy:\", accuracy_score(y_val, val_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABoosted Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch cv on random forest\n",
    "\n",
    "# Parameter grid for GridSearch\n",
    "param_grid = {'ada_tree__n_estimators': [5, 150, 300],  # , 50, 75, 100, 125, 150, 200, 250],\n",
    "              'ada_tree__learning_rate': [.5, .1]\n",
    "              }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(ada,  # Base model\n",
    "                           param_grid,  # Parameters to try\n",
    "                           cv=5,  # Apply 5-fold cross validation\n",
    "                           verbose=10,  # Print summary\n",
    "                           n_jobs=-1  # Use all available processors\n",
    "                           )\n",
    "\n",
    "# Fit the GridSearch to our training data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "classifier = grid_search.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "val_predictions = classifier.predict(X_val)\n",
    "\n",
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"val accuracy:\", accuracy_score(y_val, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_logit = pd.DataFrame(zip(X_train.columns, np.transpose(\n",
    "    log.coef_.tolist()[0])), columns=['features', 'coef'])\n",
    "coef_logit = coef_logit.sort_values(by='coef', ascending=False).reset_index()\n",
    "coef_logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_tree = pd.DataFrame(\n",
    "    X_train.columns, new_tree.feature_importances_, columns=['features'])\n",
    "coef_tree.sort_index(ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_logit[coef_logit['features'].str.contains('Pit')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ada = pd.DataFrame(zip(X_train.columns, np.transpose(\n",
    "    rfc_tree.feature_importances_)), columns=['features', 'coef'])\n",
    "coef_ada = coef_ada.sort_values(by='coef', ascending=False).reset_index()\n",
    "coef_ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_predict, y_test))\n",
    "plot_confusion_matrix(log, Scaler.transform(X_test), y_test, normalize='true')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4390d49c63237350b232469775e13f7627805befc748e27b10dc3bd013a189b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
